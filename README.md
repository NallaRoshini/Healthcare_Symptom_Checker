# 🩺 Healthcare Symptom Checker (Groq + FastAPI + React)

An AI-powered healthcare assistant web app that analyzes user symptoms and provides **probable conditions**, **recommendations**, and a **medical disclaimer** — all generated by the **Llama 3.1 model (via Groq Cloud API)**.

---

## Features

- Uses **Groq Cloud (Llama 3.1)** for intelligent medical text generation.
- **FastAPI backend** for LLM requests and structured JSON responses.
- **React (Vite)** frontend with centered modern UI.
- **Langchain-Chatgroq** integration for low-latency LLM calls.
- Optional **SQLite database** to log user symptom queries.
- Dark-themed, responsive, minimal UI with Markdown support.

---

## Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | React (Vite), React Markdown |
| **Backend** | FastAPI, Python 3.10+ |
| **AI Model** | Groq Cloud API (Llama 3.1-8b-instant) |
| **Database (optional)** | SQLite (SQLAlchemy ORM) |

---

## 🧩 Project Structure
```
Healthcare-Symptom-Checker/
│
├── backend/
│ ├── app/
│ │ ├── main.py # FastAPI entry point
│ │ ├── llm_client.py # Groq API call logic
│ │ ├── models.py # SQLAlchemy database models
│ │ ├── schemas.py # Pydantic response models
│ │ ├── database.py # SQLite database configuration
│ │ ├── init.py
│ │
│ ├── venv/ # Python virtual environment
│ ├── requirements.txt
│ └── .env # API keys & environment variables
│
├── frontend/
│ ├── src/
│ │ ├── App.jsx # React main component
│ │ ├── api.js # Frontend → Backend API calls
│ │ ├── index.css # Global centered layout
│ │ └── main.jsx
│ ├── vite.config.js
│ ├── package.json
│ └── README.md
│
└── README.md # (This file)
```

---

## Setup Instructions

### Clone the repository
```bash
https://github.com/NallaRoshini/Healthcare_Symptom_Checker.git
cd Healthcare_Symptom_Checker
```

### Backend Setup (FastAPI)
``` bash
cd backend
python -m venv venv
venv\Scripts\activate    # (Windows)
# or
source venv/bin/activate # (Mac/Linux)

pip install -r requirements.txt
```

Create a .env file inside backend/:
```ini
GROQ_API_KEY=your_groq_api_key_here
GROQ_API_BASE=https://api.groq.com
GROQ_MODEL=llama-3.1-8b-instant
DATABASE_URL=sqlite:///./symptom_records.db
```

Run the backend server
```bash
uvicorn app.main:app --reload
```

It’ll start on:
http://127.0.0.1:8000

### Frontend Setup (React + vite)
```bash
cd frontend
npm install
npm run dev
```

Your app will run on:

🌐 http://localhost:5173

### How it works

1) User enters symptom description (e.g., “I have fever and throat pain”).

2) Frontend sends this text to /api/check.

3) FastAPI builds a structured JSON prompt and calls Groq Llama 3.1.

4) LLM responds with:
```json
{
  "probable_conditions": "Pharyngitis, Common cold",
  "recommendations": "Stay hydrated, rest, use salt-water gargle",
  "disclaimer": "Educational purposes only"
}
```

#### Example Output

<img width="905" height="709" alt="image" src="https://github.com/user-attachments/assets/0dc69b7b-9bd7-4a05-aed4-23605e068d05" />
<img width="1118" height="776" alt="image" src="https://github.com/user-attachments/assets/2330a98f-d203-4a60-b757-5e8d1264e5c1" />

### API Reference
```POST /api/check```
Analyze user symptom text and return probable conditions.
```json
{
  "text": "I have a sore throat and fever for 2 days."
}
```

Response:
```json
{
  "probable_conditions": "Pharyngitis, Tonsillitis",
  "recommendations": "Rest, fluids, warm gargle.",
  "disclaimer": "Educational purposes only."
}
```

### Dependencies

#### Backend
```bash
fastapi
uvicorn[standard]
python-dotenv
langchain
langchain-groq
sqlalchemy
alembic
python-multipart
```

#### Frontend
```bash
react
react-dom
react-markdown
vite
```

### Deployment Notes
You can deploy:
>
**Backend** → Render / Railway (Free FastAPI hosting)
>
**Frontend** → Vercel / Netlify
>
Make sure to set GROQ_API_KEY as an environment variable in your deployment settings.

### Acknowledgments
1) https://console.groq.com/home
2) https://fastapi.tiangolo.com/
3) https://vite.dev/





